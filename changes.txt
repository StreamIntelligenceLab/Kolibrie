0.1.1
1. Modify whole project by making Cargo workspace
2. Modify GPU CUDA
3. Add proc_macro for GPU ```[gpu::main]```
4. Add cuda example
5. Add possibility to make a user defined function
6. Add user defined function example
7. Add 'CONCAT' keyword
8. Add indexing optimization
9. Modify WHERE clause by accept a uri in addition to variable or literal
10. Modify query by adding semicolon
11. Modify query, ability to write nested query
12. Add Datalog engine
13. Add Trie indexing for Datalog engine
14. Modify workspace split everything into parts (triple&dict -> shared, kg -> datalog)
15. Modify N3 logic by including nested rules
16. Modify N3 parser by utilize rayon
17. Modify Indexing by removing Trie algorithm and using my own from triple
18. Modify Indexing by adding Rule Index, add some examples
19. Modify knowledge Graph adding parallel processing for semi-naive
20. Modify SPARQL syntax by combining SPARQL + LP 
21. Modify SPARQL syntax make execution of SPARQL + LP (N3 logic)
22. Integrate project with Python (currently only Datalog)
23. Modify SPARQL by making CUDA as a feature (by default disabled)
24. Add ARM instructions to 'FILTER'
25. Small cleaning
26. Modify Datalog by adding inconsistency
27. Add example in Rust and Python with inconsistency
28. Fix problem with inconsistency
29. Fix SIMD part for ARM instructions
30. Modify SPARQL + LP syntax by adding multiple parameter set
31. Add parsing for machine learning SPARQL + LP + ML
32. Ability to use machine learning models
33. Modify execution, make it as a separate file
34. Add ARM support for machine learning wrapper
35. Minor fix of example with backward chaining
36. Modify machine learning execution, more depend on query
37. Add error handling
38. Modify ML handler to use MLSchema and ability to run multiple ML models
39. Modify FILTER to have such epxression: ?age > 10 && ?age < 15 or ?age < 10 || ?age > 15
40. Add multiple conclusion, add example with mqtt (real scenario)
41. Modify multiple conclusion
42. Fix mqtt real scenario
43. Modify ML handler for using different machine learning algorithms
44. Modify ML execution to make it more generic
45. Modify ML handler by making MLSchema global, clean some parts of ML
46. Minor update of ML handler
47. Fix problem with handling different ML models
48. Modify ML handler by taking and compare models from Turtle file
49. Modify FILTER by adding arithmetic epxression
50. Clean SPARQL
51. Design QueryBuilder class for functional API
52. Add into Python wrapper QueryBuilder
53. Modify License
54. Add RSP
55. Modify RULE syntax instead of N3 logic conclusion use CONSTRUCT
56. Separate RULE syntax and SPARQL syntax
57. Add tests for parser
58. Improve License
59. Add Dockerfile
60. Minor fix in ML examples
61. Minor fix of dependency vulnarability
62. Modify ML by adding ability to link OUTPUT with CONSTRUCT clause
63. Add an ML example with link OUTPUT and CONSTRUCT clause
64. Fix ML example with link OUTPUT and CONSTRUCT clause
65. Integrate RSP with QueryBuilder
66. Add tests for QueryBuilder
67. Modify wrapper of QueryBuilder by adding RSP
68. Add an example in Python for RSP
69. Add N-Triples parser
70. Add in some files license header
71. Ability to querying 10M triples
72. Improve optimizer and joining algorithm for processing 10M triples
73. Use sorted-merge join algorithm instead of nested loop for big data
74. Modify sorted-merge join algorithm by using IDs instead of string
75. Integrate RSP with a parser
76. Minor fix of RULE syntax
77. Modify parser for execution when RSP
78. Add Hierarchy reasoning
79. Major update hierarchy reasoning
80. Add LIMIT
81. Major fix of RULE syntax
82. Update README and minor change
83. Add CLI for Kolibrie
84. Update one dependency to a new version
85. Update dependencies for parsing
86. Add combination stream
87. Add new queries for processing 10M triples
88. Improve volcano optimizer
89. Improve volcano optimizer by using IDs instead of string
90. Improve volcano optimizer by improving cardinality estimator and join algorithms
91. Minor change

0.1.0
1. Parsing RDF/XML
2. Parsing Turtle
3. Parsing N3
4. Desing SQL syntax
5. Desing JOINing
5. Add aggregation functions (MIN, MAX, AVG, SUM)
6. Add 'FILTER' keyword
7. Add 'INSERT' keyword
8. Ability to make 'SELECT *' or select all
9. Add 'VALUES' keyword
10. Ability to read files (dataset files)
12. Add benchmark
13. Add unit tests
14. Add examples
15. Modify join by using rayon
16. Modify parse_rdf by using rayon and crossbeam
17. Modify join by uisng hash join and use rayon for parallel computation
18. Add volcano optimizer and cardinality estimator
19. Add knowledge graph
20. Add forward and backward chaining
21. Ability to process N3 logic 
22. Add IStream, RStream, DStream
23. Add sliding window
24. Add policies (window close policy, content change policy, non-empty content policy, periodic policy)
25. Add REST API for database engine
26. Ability to generate synthetic dataset
